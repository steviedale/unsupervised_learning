{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureWrapper:\n",
    "    NAME = 'GMM'\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.model = GaussianMixture(n_components=n_components)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "class KMeansWrapper:\n",
    "    NAME = 'KMeans'\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'mnist'\n",
    "DATASET_NAME = 'wine_quality'\n",
    "\n",
    "# DIM_RED_METHOD = 'LLE'\n",
    "DIM_RED_METHOD = 'PCA'\n",
    "# DIM_RED_METHOD = 'ICA'\n",
    "\n",
    "METHOD = GaussianMixtureWrapper\n",
    "# METHOD = KMeansWrapper\n",
    "K_FOLDS = 5\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'wine_quality':\n",
    "    DATASET_STR = 'Wine Quality'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    DATASET_STR = 'MNIST'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = f'results/step_3/{DATASET_NAME}/{METHOD.NAME}_{DIM_RED_METHOD}_metrics.csv'\n",
    "if os.path.exists(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df.set_index('num_components', inplace=True)\n",
    "    df['num_components'] = df.index\n",
    "else:\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 3: 15 instances\n",
      "Label 4: 130 instances\n",
      "Label 5: 1152 instances\n",
      "Label 6: 1758 instances\n",
      "Label 7: 719 instances\n",
      "Label 8: 143 instances\n",
      "Label 9: 1 instances\n"
     ]
    }
   ],
   "source": [
    "# get the number of instances of each label in y\n",
    "for i in np.unique(y_train):\n",
    "    print(f'Label {i}: {np.sum(y_train == i)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/19 [00:01<00:20,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/19 [00:02<00:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 3/19 [00:04<00:22,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4/19 [00:06<00:23,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 5/19 [00:08<00:25,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 6/19 [00:10<00:24,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 7/19 [00:12<00:24,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 8/19 [00:15<00:24,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 9/19 [00:18<00:24,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 10/19 [00:21<00:24,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 11/19 [00:24<00:21,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 12/19 [00:26<00:19,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 13/19 [00:30<00:17,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 14/19 [00:34<00:16,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 15/19 [00:39<00:15,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 16/19 [00:44<00:12,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 17/19 [00:50<00:09,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 18/19 [00:55<00:04,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:00<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "n = X_train.shape[0] // K_FOLDS\n",
    "metrics = {\n",
    "    'calinski_harabasz_score': calinski_harabasz_score,\n",
    "    'davies_bouldin_score': davies_bouldin_score,\n",
    "    'adjusted_rand_score': adjusted_rand_score,\n",
    "    'adjusted_mutual_info_score': adjusted_mutual_info_score,\n",
    "    'homogeneity_score': homogeneity_score,\n",
    "    'completeness_score': completeness_score,\n",
    "    'silhouette_score': silhouette_score,\n",
    "}\n",
    "\n",
    "if DATASET_NAME == 'wine_quality':\n",
    "    range_ = range(2, 21)\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    range_ = range(2, 21)\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')\n",
    "\n",
    "for components in tqdm(range_):\n",
    "    if components in df.index:\n",
    "        continue\n",
    "    print(components)\n",
    "    metric_lists = {k: [] for k in metrics.keys()}\n",
    "    training_time_list = []\n",
    "    evaluation_time_list = []\n",
    "    for i in range(K_FOLDS):\n",
    "        X_train_k = np.concatenate([X_train[:i * n], X_train[(i + 1) * n:]])\n",
    "        y_train_k = np.concatenate([y_train[:i * n], y_train[(i + 1) * n:]])\n",
    "        X_test_k = X_train[i * n:(i + 1) * n]\n",
    "        y_test_k = y_train[i * n:(i + 1) * n]\n",
    "\n",
    "        model = METHOD(components)\n",
    "        t0 = time.perf_counter()\n",
    "        model.fit(X_train_k)\n",
    "        t1 = time.perf_counter()\n",
    "        training_time_list.append(t1 - t0)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        y_test_pred = model.predict(X_test_k) \n",
    "        t1 = time.perf_counter()\n",
    "        evaluation_time_list.append(t1 - t0)\n",
    "  \n",
    "        for metric_str, metric in metrics.items():\n",
    "            if metric_str in ['adjusted_rand_score', 'adjusted_mutual_info_score', 'homogeneity_score', 'completeness_score']:\n",
    "                metric_lists[metric_str].append(metric(y_test_k, y_test_pred))\n",
    "            else:\n",
    "                metric_lists[metric_str].append(metric(X_test_k, y_test_pred))\n",
    "\n",
    "    df.loc[components, 'num_components'] = components\n",
    "    df.loc[components, 'training_time_mean'] = np.mean(training_time_list)\n",
    "    df.loc[components, 'training_time_std'] = np.std(training_time_list)\n",
    "    df.loc[components, 'evaluation_time_mean'] = np.mean(evaluation_time_list)\n",
    "    df.loc[components, 'evaluation_time_std'] = np.std(evaluation_time_list)\n",
    "    for metric_str, metric_list in metric_lists.items():\n",
    "        df.loc[components, f'{metric_str}_mean'] = np.mean(metric_list)\n",
    "        df.loc[components, f'{metric_str}_std'] = np.std(metric_list)\n",
    "df['num_components'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    os.makedirs(os.path.dirname(df_path), exist_ok=True)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
