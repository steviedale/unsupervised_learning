{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureWrapper:\n",
    "    NAME = 'GMM'\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.model = GaussianMixture(n_components=n_components)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "class KMeansWrapper:\n",
    "    NAME = 'KMeans'\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'mnist'\n",
    "# DATASET_NAME = 'wine_quality'\n",
    "\n",
    "# DIM_RED_METHOD = 'LLE'\n",
    "DIM_RED_METHOD = 'PCA'\n",
    "\n",
    "METHOD = GaussianMixtureWrapper\n",
    "# METHOD = KMeansWrapper\n",
    "K_FOLDS = 5\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'wine_quality':\n",
    "    DATASET_STR = 'Wine Quality'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    DATASET_STR = 'MNIST'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = f'results/step_3/{DATASET_NAME}/{METHOD.NAME}_{DIM_RED_METHOD}_metrics.csv'\n",
    "if os.path.exists(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df.set_index('num_components', inplace=True)\n",
    "    df['num_components'] = df.index\n",
    "else:\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of instances of each label in y\n",
    "for i in np.unique(y_train):\n",
    "    print(f'Label {i}: {np.sum(y_train == i)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0] // K_FOLDS\n",
    "metrics = {\n",
    "    'calinski_harabasz_score': calinski_harabasz_score,\n",
    "    'davies_bouldin_score': davies_bouldin_score,\n",
    "    'adjusted_rand_score': adjusted_rand_score,\n",
    "    'adjusted_mutual_info_score': adjusted_mutual_info_score,\n",
    "    'homogeneity_score': homogeneity_score,\n",
    "    'completeness_score': completeness_score,\n",
    "    'silhouette_score': silhouette_score,\n",
    "}\n",
    "\n",
    "if DATASET_NAME == 'wine_quality':\n",
    "    range_ = range(2, 21)\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    range_ = range(2, 21)\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')\n",
    "\n",
    "for components in tqdm(range_):\n",
    "    if components in df.index:\n",
    "        continue\n",
    "    print(components)\n",
    "    metric_lists = {k: [] for k in metrics.keys()}\n",
    "    training_time_list = []\n",
    "    evaluation_time_list = []\n",
    "    for i in range(K_FOLDS):\n",
    "        X_train_k = np.concatenate([X_train[:i * n], X_train[(i + 1) * n:]])\n",
    "        y_train_k = np.concatenate([y_train[:i * n], y_train[(i + 1) * n:]])\n",
    "        X_test_k = X_train[i * n:(i + 1) * n]\n",
    "        y_test_k = y_train[i * n:(i + 1) * n]\n",
    "\n",
    "        model = METHOD(components)\n",
    "        t0 = time.perf_counter()\n",
    "        model.fit(X_train_k)\n",
    "        t1 = time.perf_counter()\n",
    "        training_time_list.append(t1 - t0)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        y_test_pred = model.predict(X_test_k) \n",
    "        t1 = time.perf_counter()\n",
    "        evaluation_time_list.append(t1 - t0)\n",
    "  \n",
    "        for metric_str, metric in metrics.items():\n",
    "            if metric_str in ['adjusted_rand_score', 'adjusted_mutual_info_score', 'homogeneity_score', 'completeness_score']:\n",
    "                metric_lists[metric_str].append(metric(y_test_k, y_test_pred))\n",
    "            else:\n",
    "                metric_lists[metric_str].append(metric(X_test_k, y_test_pred))\n",
    "\n",
    "    df.loc[components, 'num_components'] = components\n",
    "    df.loc[components, 'training_time_mean'] = np.mean(training_time_list)\n",
    "    df.loc[components, 'training_time_std'] = np.std(training_time_list)\n",
    "    df.loc[components, 'evaluation_time_mean'] = np.mean(evaluation_time_list)\n",
    "    df.loc[components, 'evaluation_time_std'] = np.std(evaluation_time_list)\n",
    "    for metric_str, metric_list in metric_lists.items():\n",
    "        df.loc[components, f'{metric_str}_mean'] = np.mean(metric_list)\n",
    "        df.loc[components, f'{metric_str}_std'] = np.std(metric_list)\n",
    "df['num_components'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    os.makedirs(os.path.dirname(df_path), exist_ok=True)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
