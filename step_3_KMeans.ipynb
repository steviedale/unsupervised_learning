{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "from sklearn.metrics import completeness_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureWrapper:\n",
    "    NAME = 'GMM'\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.model = GaussianMixture(n_components=n_components)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def bic(self, X):\n",
    "        return self.model.bic(X)\n",
    "\n",
    "    def aic(self, X):\n",
    "        return self.model.aic(X)\n",
    "\n",
    "class KMeansWrapper:\n",
    "    NAME = 'KMeans'\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.model.fit(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def inertia(self):\n",
    "        return self.model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'mnist'\n",
    "# DATASET_NAME = 'wine_quality'\n",
    "\n",
    "# DIM_RED_METHOD = 'LLE'\n",
    "# DIM_RED_METHOD = 'PCA'\n",
    "DIM_RED_METHOD = 'ICA'\n",
    "\n",
    "# METHOD = GaussianMixtureWrapper\n",
    "METHOD = KMeansWrapper\n",
    "K_FOLDS = 5\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == 'wine_quality':\n",
    "    DATASET_STR = 'Wine Quality'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    DATASET_STR = 'MNIST'\n",
    "    X_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_train.pkl', 'rb'))\n",
    "    y_train = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_train.pkl', 'rb'))\n",
    "    X_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/X_test.pkl', 'rb'))\n",
    "    y_test = pickle.load(open(f'transformed_data/{DATASET_NAME}/{DIM_RED_METHOD}/y_test.pkl', 'rb'))\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = f'results/step_3/{DATASET_NAME}/{METHOD.NAME}_{DIM_RED_METHOD}_metrics.csv'\n",
    "if os.path.exists(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df.set_index('num_components', inplace=True)\n",
    "    df['num_components'] = df.index\n",
    "else:\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 5923 instances\n",
      "Label 1: 6742 instances\n",
      "Label 2: 5958 instances\n"
     ]
    }
   ],
   "source": [
    "# get the number of instances of each label in y\n",
    "for i in np.unique(y_train):\n",
    "    print(f'Label {i}: {np.sum(y_train == i)} instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:02<00:38,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:07<00:51,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:13<00:59,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:22<01:12,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:32<01:16,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:42<01:17,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:50<01:07,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:58<00:56,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [01:03<00:42,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [01:12<00:38,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [01:27<00:40, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [01:45<00:37, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [02:25<00:41, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [03:04<00:26, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:18<00:00, 17.25s/it]\n"
     ]
    }
   ],
   "source": [
    "n = X_train.shape[0] // K_FOLDS\n",
    "metrics = {\n",
    "    'calinski_harabasz_score': calinski_harabasz_score,\n",
    "    'davies_bouldin_score': davies_bouldin_score,\n",
    "    'adjusted_rand_score': adjusted_rand_score,\n",
    "    'adjusted_mutual_info_score': adjusted_mutual_info_score,\n",
    "    'homogeneity_score': homogeneity_score,\n",
    "    'completeness_score': completeness_score,\n",
    "    'silhouette_score': silhouette_score,\n",
    "}\n",
    "\n",
    "if DATASET_NAME == 'wine_quality':\n",
    "    range_ = list(range(2, 21, 2))\n",
    "    range_ += [25, 50, 75, 100, 195]\n",
    "elif DATASET_NAME == 'mnist':\n",
    "    range_ = list(range(2, 21, 2))\n",
    "    range_ += [25, 50, 75, 100, 195]\n",
    "else:\n",
    "    raise ValueError(f'Invalid dataset name {DATASET_NAME}')\n",
    "\n",
    "for components in tqdm(range_):\n",
    "    if components in df.index:\n",
    "        continue\n",
    "    print(components)\n",
    "    metric_lists = {k: [] for k in metrics.keys()}\n",
    "    training_time_list = []\n",
    "    evaluation_time_list = []\n",
    "    inertia_list = []\n",
    "    aic_list = []\n",
    "    bic_list = []\n",
    "    for i in range(K_FOLDS):\n",
    "        X_train_k = np.concatenate([X_train[:i * n], X_train[(i + 1) * n:]])\n",
    "        y_train_k = np.concatenate([y_train[:i * n], y_train[(i + 1) * n:]])\n",
    "        X_test_k = X_train[i * n:(i + 1) * n]\n",
    "        y_test_k = y_train[i * n:(i + 1) * n]\n",
    "\n",
    "        model = METHOD(components)\n",
    "        t0 = time.perf_counter()\n",
    "        model.fit(X_train_k)\n",
    "        t1 = time.perf_counter()\n",
    "        training_time_list.append(t1 - t0)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        y_test_pred = model.predict(X_test_k) \n",
    "        t1 = time.perf_counter()\n",
    "        evaluation_time_list.append(t1 - t0)\n",
    "  \n",
    "        if METHOD.NAME == 'KMeans':\n",
    "            inertia_list.append(model.inertia())\n",
    "        elif METHOD.NAME == 'GMM':\n",
    "            aic_list.append(model.aic(X_test))\n",
    "            bic_list.append(model.bic(X_test))\n",
    "\n",
    "        for metric_str, metric in metrics.items():\n",
    "            if metric_str in ['adjusted_rand_score', 'adjusted_mutual_info_score', 'homogeneity_score', 'completeness_score']:\n",
    "                metric_lists[metric_str].append(metric(y_test_k, y_test_pred))\n",
    "            else:\n",
    "                metric_lists[metric_str].append(metric(X_test_k, y_test_pred))\n",
    "\n",
    "    if METHOD.NAME == 'KMeans':\n",
    "        df.loc[components, 'inertia_mean'] = np.mean(inertia_list)\n",
    "        df.loc[components, 'inertia_std'] = np.std(inertia_list)\n",
    "    elif METHOD.NAME == 'GMM':\n",
    "        df.loc[components, 'aic_mean'] = np.mean(aic_list)\n",
    "        df.loc[components, 'aic_std'] = np.std(aic_list)\n",
    "        df.loc[components, 'bic_mean'] = np.mean(bic_list)\n",
    "        df.loc[components, 'bic_std'] = np.std(bic_list)\n",
    "\n",
    "    df.loc[components, 'num_components'] = components\n",
    "    df.loc[components, 'training_time_mean'] = np.mean(training_time_list)\n",
    "    df.loc[components, 'training_time_std'] = np.std(training_time_list)\n",
    "    df.loc[components, 'evaluation_time_mean'] = np.mean(evaluation_time_list)\n",
    "    df.loc[components, 'evaluation_time_std'] = np.std(evaluation_time_list)\n",
    "    for metric_str, metric_list in metric_lists.items():\n",
    "        df.loc[components, f'{metric_str}_mean'] = np.mean(metric_list)\n",
    "        df.loc[components, f'{metric_str}_std'] = np.std(metric_list)\n",
    "df['num_components'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    os.makedirs(os.path.dirname(df_path), exist_ok=True)\n",
    "    df.to_csv(df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
